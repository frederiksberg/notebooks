{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udtræk tekst fra Lokalplaner\n",
    "Henter tekst ud af PDF'er fra plansystem og lægger det i en PostgreSQL tabel.\n",
    "\n",
    "## 1. Klargør tabeller i databasen\n",
    "\n",
    "Hent alle lokalplaner fra plansystems-WFS til PostgreSQL database:\n",
    "\n",
    "```bash\n",
    "ogr2ogr -f PostgreSQL PG:\"dbname=xx host=xx port=xx user=xx password=xx\" WFS:\"http://geoservice.plansystem.dk/wfs?version=1.0.0\" pdk:lokalplan -lco SCHEMA=proj_lokalplan_dokument -lco GEOMETRY_NAME=the_geom -nln \"lokalplan\" -a_srs \"EPSG:25832\"\n",
    "```\n",
    "\n",
    "Lav tabel i databasen til at indsætte planid, status og tilhørende dokumenttekst\n",
    "```sql\n",
    "# Lav skema og tabel\n",
    "create schema elasticsearch;\n",
    "\n",
    "create table elasticsearch.lokalplan_dokument (\n",
    "\tgid serial primary key not null,\n",
    "\tplanid int4,\n",
    "\tplannavn varchar,\n",
    "\tstatus varchar,\n",
    "\tdocument text\n",
    ")\n",
    "\n",
    "## indsæt plandata ind i lokalplan_dokument\n",
    "insert into elasticsearch.lokalplan_dokument(planid, plannavn, status)\n",
    "SELECT planid, plannavn, status\n",
    "FROM job_plandatadk.lokalplan\n",
    "where STATUS in ('V', 'F') and AKTUEL = true and komnr = 147 and doklink is not null;\n",
    "```\n",
    "\n",
    "## 2. Opdateringer\n",
    "Lokalplaner kan have følgende statuser - kladde, forslag, vedtage og aflyst. Vi er kun interesseret at oprette, opdatere eller fjerne lokalplandokumenter i ElasticSearch indexet når der sker ændring i planstatus. Ligeledes skal de data der trækkes fra WFS tilrettes i PostgreSQL. Opdateringsfrekvensen er selvfølgelig afgørende for om en plan kan springe en status over og som udgangspunkt kan opdateringen sættes til at ske en gang om måneden. Følgende scenarier gør sig gældende: \n",
    "#### Oprettes\n",
    "* Planer der ændre status fra kladde til forslag\n",
    "* Planer med planid som ikke allrede eksisterer (springer status over pga. opdateringfrekvensen)\n",
    "\n",
    "#### Opdateres\n",
    "* Planer der ændre status fra forslag til vedtaget\n",
    "\n",
    "#### Slettes\n",
    "* Planer der ændre status til aflyst\n",
    "\n",
    "planid vil være det samme for en plan der ændre status, men i tabellen angives hvilken plan som er gældende i kolonnen aktuel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andersbarfod/anaconda/envs/plandata/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.23) or chardet (2.3.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "/Users/andersbarfod/anaconda/envs/plandata/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import io\n",
    "import PyPDF2\n",
    "import logging\n",
    "import psycopg2\n",
    "import textract\n",
    "import os\n",
    "from sqlalchemy import create_engine, Table, MetaData, update, select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/andersbarfod/Documents/python/')\n",
    "import connections as con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='logfile.log', filemode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@rqaiserr/how-to-convert-pdfs-into-searchable-key-words-with-python-85aab86c544f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf(url, folder):\n",
    "    \"\"\"\n",
    "    Download pdf from url to folder\n",
    "    \"\"\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        logging.warning(e)\n",
    "    pdf_name = url.split('/')[-1]\n",
    "    path = folder + pdf_name\n",
    "    with open(path, 'wb') as file:\n",
    "        file.write(r.content)\n",
    "    return pdf_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_document(url, temp_folder='./', language='dan'):\n",
    "    \"\"\"\n",
    "    Get pdf documents from URL and extract the text. \n",
    "    If the pdf doesn't contain text textract is used to \n",
    "    OCR scan the document, which entails temporary downloads of pdf's.\n",
    "    The function uses logging of exceptions, so make sure to setop logging basic config.\n",
    "    \n",
    "    logging.basicConfig(filename='logfile.log', filemode='w')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        logging.warning(e)\n",
    "    # Convert to in-memory binary streams and read pdf\n",
    "    pdf_file = io.BytesIO(r.content)\n",
    "    pdfReader = PyPDF2.PdfFileReader(pdf_file, strict=False)\n",
    "\n",
    "    # Discerning the number of pages will allow us to parse through all the pages\n",
    "    num_pages = pdfReader.numPages\n",
    "    count = 0\n",
    "    text = \"\"\n",
    "    # The while loop will read each page\n",
    "    while count < num_pages:\n",
    "        try:\n",
    "            pageObj = pdfReader.getPage(count)\n",
    "            count +=1\n",
    "            text += pageObj.extractText()\n",
    "        except Exception as e:\n",
    "            logging.warning(e)\n",
    "            print(e, url)\n",
    "    #If the belov returns as False, we run the OCR library textract to \n",
    "    # convert scanned/image based PDF files into text         \n",
    "    if text != \"\":\n",
    "        text = text\n",
    "    else:\n",
    "        try:\n",
    "            # Download pdf to disk in order to use textract (might be possible to do in-memory)\n",
    "            filename = download_pdf(url, temp_folder)\n",
    "            text = textract.process(temp_folder + filename, method='tesseract', language=language)\n",
    "            text = text.decode('utf-8')\n",
    "            if os.path.exists(filename):\n",
    "                os.remove(filename)\n",
    "        except Exception as e:\n",
    "            logging.warning(e)\n",
    "            print(e, url)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output til PostgreSQL\n",
    "Ovenstående `get_document()` funktions bruges til at opdatere `plan_dokument` tabellen med teksten fra lokalplanerne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = con.engine('production')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plan = Table('lokalplan_dokument', metadata, autoload=True, autoload_with=engine, schema='elasticsearch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_table(komkode):\n",
    "    sql = '''\n",
    "        select PLANID, STATUS, doklink\n",
    "        FROM job_plandatadk.lokalplan\n",
    "        where STATUS in ('V', 'F') and AKTUEL = true and komnr = {} and doklink is not null\n",
    "        '''.format(komkode)\n",
    "    result_set = connection.execute(sql)  \n",
    "    for r in result_set:  \n",
    "        plan_update = plan.update().values(document=get_document(r['doklink'])).where(plan.c.planid == r['planid'] and plan.c.status == r['status'])\n",
    "        engine.execute(plan_update)\n",
    "        logging.info('Indlæst: %s', plan.c.planid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'/Contents' https://dokument.plandata.dk/20_3287138_1516291087510.pdf\n",
      "'/Contents' https://dokument.plandata.dk/20_3287138_1516291087510.pdf\n",
      "'/Contents' https://dokument.plandata.dk/20_3287138_1516291087510.pdf\n",
      "name 'os' is not defined https://dokument.plandata.dk/20_1062041_APPROVED_1298984717792.pdf\n",
      "name 'os' is not defined https://dokument.plandata.dk/20_1108674_APPROVED_1293720247017.pdf\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    update_table(147)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
